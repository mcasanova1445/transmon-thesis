\chapter{Información cuántica}

En esta sección introduciremos las bases matemáticas fundamentales para empezar a trabajar con la Teoría de Información Cuántica. Se dará una breve introducción a la notación de Dirac y su aplicación en la Mecánica Cuántica (QM). Una vez establecidas las bases matemáticas se describirán los Postulados de la QM: Descripción del estado de un sistema, descripción de cantidades físicas, medición de cantidades físicas, colapso del estado cuántico, evolución temporal, postulado de simetrización y variables de espín. Se definirá el entrelazamiento cuántico, su importancia en el cómputo cuántico y los sistemas de dos niveles. Finalmente, explicaremos las bases de la computación cuántica y daremos una introducción a los sistemas cuánticos abiertos y el Lindbladiano.

\section{Operadores lineales}

Un operador $\hat{A}: \mathcal{V}_1 \rightarrow \mathcal{V}_2$ es lineal si para todo par de vectores $\mathbf{v}, \mathbf{w} \in \mathcal{V}_1$ y para un escalar $\alpha$, se cumple que

\begin{align}
    \hat{A} (\mathbf{v} + \mathbf{w}) &= \hat{A} \mathbf{v} + \hat{A} \mathbf{w} \\
    \hat{A} (\alpha \mathbf{v}) &= \alpha \hat{A} \mathbf{v} .
\end{align}

En QM se utiliza extensamente la transpuesta hermítica o transpuesta conjugada $\hat{A}^\dagger$ de operadores lineales $\hat{A}$. En la representación matricial $[A_{ij}]$ de los operadores lineales $\hat{A}$, la transpuesta hermítica se define de la siguiente manera

\begin{equation}
    \hat{A}^\dagger = ([A_{ij}]^T)^* = [A_{ji}]^* ,
\end{equation}

Donde $\cdot^*$ representa el complejo conjugado de cada una de las entradas de la matriz y $\cdot^T$ representa la transpuesta de la matriz.

\section{Delta de Kronecker}

La delta de Kronecker $\delta_{ij}$ es un símbolo que representa dos posibles valores, dependiendo de sus subíndices,

\begin{equation}
    \delta_{ij} =
    \begin{cases}
        1 & \text{si } i = j \\
        0 & \text{si } i \neq j
    \end{cases} .
\end{equation}

Dado que el símbolo sólo es diferente de cero cuando sus índices son iguales, las sumas que incluyen la delta de Kronecker pueden ser simplificadas fácilmente.

\begin{equation}
    \sum\limits_j \delta_{ij} B_j = 0 B_1 + 0 B_2 + ... + 1 B_n + ... = B_n .
\end{equation}

En varios de los cálculos de este libro aparecerán sumas de este tipo. La delta de Kronecker también es importante porque el operador identidad se puede definir a partir de ella, de la siguiente manera

\begin{equation}
    \mathds{1} = [\delta_{ij}] .
\end{equation}

\section{Operadores hermíticos}

Los operadores hermíticos $\hat{H}$ son operadores tales que

\begin{equation}
    \hat{H} = \hat{H}^\dagger .
\end{equation}

Es decir, $\hat{H}$ es un operador hermítico si es igual a su transpuesta conjugada. Estos operadores cumplen con la propiedad de que todos sus autovalores son reales. En la representación matricial, los operadores hermíticos corresponden a matrices cuadradas cuyos elementos de la diagonal son reales, y los términos fuera de la diagonal inferiores son el conjugado complejo de los términos fuera de la diagonal superiores. Todo operador hermítico puede ser diagonalizado con un operador unitario.

\begin{equation}
    \hat{H} = \hat{U} \hat{D} \hat{U}^\dagger .
\end{equation}

\section{Operadores unitarios}

Un operador unitario $\hat{U}$ es un operador tal que

\begin{equation}
    \hat{U} \hat{U}^\dagger = \hat{U}^\dagger \hat{U} = \mathds{1} .
\end{equation}

Es decir, un operador unitario $\hat{U}$ es aquel cuya inversa es igual a su transpueta hermítica. Los operadores unitarios tienen determinantes de módulo igual a 1. Si el determinante de un operador unitario es real y positivo, es decir, igual a 1, entonces el operador es un operador unitario especial. Los operadores unitarios pueden ser escritos en función de operadores hermíticos de la siguiente manera:

\begin{equation}
    \hat{U} = e^{i\hat{H}} ,
\end{equation}

Donde $\hat{U}$ es un operador unitario y $\hat{H}$ es un operador hermítico. Los operadores unitarios, además, preservan las trazas y las normas. Es decir:

\begin{align}
    \norm{\hat{U} \mathbf{v}} &= \norm{\mathbf{v}} \\
    Tr(\hat{U} \hat{A}) &= Tr(\hat{A}) .
\end{align}

Todo operador unitario puede ser diagonalizado con otro operador unitario.

\begin{equation}
    \hat{U} = \hat{V} \hat{D} \hat{V}^\dagger .
\end{equation}

\section{Conmutador y anticonmutador}

Estas son operaciones comunes en la QM y revelan propiedades importantes de los operadores involucrados. Sean dos operadores $\hat{A}$ y $\hat{B}$, entonces definimos:

\begin{enumerate}
    \item Conmutador:

        \begin{equation}
            [\hat{A},\hat{B}] = \hat{A} \hat{B} - \hat{B} \hat{A} .
        \end{equation}

    \item Anticonmutador:

        \begin{equation}
            \{A,B\} = A B + B A .
        \end{equation}
\end{enumerate}

Si $[\hat{A},\hat{B}] = 0$, $\hat{A}$ y $\hat{B}$ conmutan entre sí, pues $\hat{A}\hat{B} = \hat{B}\hat{A}$. De igual manera, si $\{\hat{A},\hat{B}\} = 0$, se dice que anticonmutan, ya que $\hat{A}\hat{B} = -\hat{B}\hat{A}$. Si dos operadores conmutan, ellos realizarán la misma transformación compuesta sin importar el orden en que se apliquen. Si dos operadores anticonmutan, invertir el orden en el que se aplican introduce una fase de $\pi$.

\begin{align}
    [\hat{A},\hat{B}] &= 0 \implies \hat{A} \hat{B} = \hat{B} \hat{A} \\
    \{\hat{A},\hat{B}\} &= 0 \implies \hat{A} \hat{B} = - \hat{B} \hat{A} .
\end{align}

Como ejemplo de la importancia del conmutador y el anticonmutador, consideremos la transformación $\mathcal{E}_U(\hat{H}) = \hat{U} \hat{H} \hat{U}^\dagger$, donde $\hat{U}$ es un operador unitario y $\hat{H}$ es un operador lineal tal que $[\hat{H},\hat{U}] = 0$, resulta que

\begin{equation}
    \mathcal{E}_U(\hat{H}) = \hat{U} \hat{H} \hat{U}^\dagger = \hat{H} \hat{U} \hat{U}^\dagger = \hat{H} \mathds{1} = \hat{H} .
\end{equation}

Es decir, $\hat{H}$ es simétrico o invariante con respecto a $\mathcal{E}_U(\hat{H})$. Por otro lado, si $\{\hat{H},\hat{U}\} = 0$, entonces

\begin{equation}
    \mathcal{E}_U(\hat{H}) = \hat{U} \hat{H} \hat{U}^\dagger = - \hat{H} \hat{U} \hat{U}^\dagger = - \hat{H} \mathds{1} = - \hat{H} .
\end{equation}

Es decir, $\hat{H}$ es antisimétrico con respecto a $\mathcal{E}_U(\hat{H})$. En otras palabras, $\mathcal{E}_U(\hat{H})$ invierte la fase de $\hat{H}$.

\section{Espacios de Hilbert}

Sea $\mathcal{V}$ un espacio vectorial, real o complejo, y consideremos una función $\norm{\cdot}: \mathcal{V} \rightarrow \mathds{R}$ que denominaremos norma si satisface los siguientes axiomas:

\begin{enumerate}
    \item Positividad: La norma es una función definida positiva, es decir, para cualquier vector $\mathbf{v} \in \mathcal{V}$ se cumple que

        \begin{equation}
            \norm{\mathbf{v}} \geq 0
        \end{equation}

    \item Escalamiento: Sea $\lambda$ un escalar arbitrario de $\mathcal{V}$, es decir, un número real o complejo, según aplique. Consideremos un vector $\mathbf{v} \in \mathcal{V}$, entonces se cumple que

        \begin{equation}
            \norm{\lambda \mathbf{v}} = \abs{\lambda} \norm{\mathbf{v}}
        \end{equation}

    \item Desigualdad triangular: La suma de la norma de dos vectores cualesquiera $\mathbf{v}, \mathbf{w} \in \mathcal{V}$ siempre es mayor o igual que la suma de la norma de estos, siendo igual en el caso en el caso en que estos vectores son paralelos.

        \begin{equation}
            \norm{\mathbf{v} + \mathbf{w}} \leq \norm{\mathbf{v}} + \norm{\mathbf{w}}
        \end{equation}

\end{enumerate}

La estructura algebraica $\mathcal{N} = \{\mathcal{V}, \norm{\cdot}\}$ compuesta por un espacio vectorial $\mathcal{V}$ y una norma $\norm{\cdot}$ recibe el nombre de espacio normado.

Sea $\mathit{V}$ un espacio vectorial complejo y la función $\langle \cdot | \cdot \rangle: \mathit{V} \times \mathit{V} \rightarrow \mathds{C}$ una función sesquilineal, positiva, no degenerada y simétrica respecto a la conjugación compleja, entonces diremos que esta función define un producto escalar. La propiedad de sesquilinealidad se refiere a que el funcional $\langle \cdot | \cdot \rangle$ es antilineal en el primer argumento y lineal en el segundo. En concreto, la sesquilinealidad satisface la siguiente igualdad

\begin{equation}
    \langle \sum_i \alpha_i \mathbf{v}_i | \sum_j \beta_j \mathbf{w}_j \rangle = \sum_i \sum_j \alpha_i^* \beta_j \langle \mathbf{v}_i | \mathbf{w}_j \rangle
\end{equation}

La propiedad de positividad se refiere a que $\langle \mathbf{v} | \mathbf{v} \rangle > 0$ para cualquier $\mathbf{v} \in \mathit{V}$ no nulo. La propiedad de no degenerado se refiere a que un único vector cumple la relación $\langle \mathbf{w} | \mathbf{w} \rangle$, el cual es el vector nulo. La propiedad de simetría ante la cojugación compleja se refiere a que el producto escalar satisface la siguiente propiedad

\begin{equation}
    \langle \mathbf{v} | \mathbf{w} \rangle = \langle \mathbf{w} | \mathbf{v} \rangle^*
\end{equation}

La estructura algebraica $\mathcal{P} = \{\mathit{V}, \langle \cdot | \cdot \rangle\}$ compuesta por un espacio vectorial $\mathit{V}$ y un producto escalar $\langle \cdot | \cdot \rangle$ recibe el nombre de espacio de pre-Hilbert. Estos espacios son considerados como casos particulares de espacios normados, ya que la norma es inducida por el producto escalar de la siguiente manera

\begin{equation}
    \norm{\mathbf{v}} = \sqrt{\langle \mathbf{v} | \mathbf{v} \rangle} \quad \forall \mathbf{v} \in \mathit{V}
\end{equation}

Ahora introduciremos otros conceptos necesarios para definir un espacio de Hilbert:

\begin{enumerate}
    \item Convergencia fuerte: Sea $\{\mathbf{v}_n\}^{n \in N}$ una sucesión cualquiera en un espacio normado $\mathcal{N}$, diremos que diche sucesión converge fuertemente a un vector $v \in \mathcal{V}$ siempre que

        \begin{equation}
            \lim_{n \to \infty} \norm{\mathbf{v}_n - \mathbf{v}} = 0
        \end{equation}

    \item Convergencia débil: Sea $\{\mathbf{v}_n\}^{n \in N}$ una sucesión cualquiera en un espacio de pre-Hilbert $\mathcal{P}$, diremos que dicha sucesión converge débilmente a un vector $\mathbf{v} \in \mathit{V}$ siempre que

        \begin{equation}
            \lim_{n \to \infty} \langle \mathbf{v}_n | \mathbf{w} \rangle = \langle \mathbf{v} | \mathbf{w} \rangle
        \end{equation}

        Resulta  claro que la convergencia débil no implica la convergencia fuerte, pero la convergencia fuerte sí implica la convergencia débil.
\end{enumerate}

El ordenamiento de una sucesión puede ser un factor determinante para su convergencia. Las sucesiones de Cauchy son aquellas en las que el ordenamiento no afecta la convergencia. Es decir, son aquellas sucesiones que cumplen que

\begin{equation}
    \lim_{n,m \to \infty} \norm{\mathbf{v}_n - \mathbf{v}_m} = 0
\end{equation}

Todas las sucesiones fuertemente convergentes son de Cauchy, sin embargo, en general, lo recíproco no es cierto. La razón es que en algunas sucesiones en $\mathcal{N}$ convergen a un vector que no pertenece a $\mathcal{N}$. Un espacio normado es completo si toda sucesión de Cauchy converge fuertemente en él. Todo espacio normado $\mathcal{N}$ y completo recibe el nombre de espacio de Banach $\mathcal{B}$, y todo espacio de pre-Hilbert $\mathcal{P}$ y completo recibe el nombre de espacio de Hilbert $\mathcal{H}$.

Finalmente, un espacio de Hilbert separable es aquel cuya base puede ser generado por una base contable. Una base contable es una base con la cardinalidad de algún subconjunto de los números naturales. En otras palabra, es una base cuyos elementos se pueden contar o enumerar. Esto implica que una base contable debe ser finita o infinita discreta.

\section{Estados cuánticos}

Un sistema físico es aquel que consta de fuentes y campos que interactúan entre sí, y a partir del cual será posible extraer o transmitir algún tipo de información. Aquellas propiedades de un sistema físico que sean susceptibles a la medida reciben el nombre de observables o magnitudes físicas. No todas las propiedades de un sistema físico son independientes, unas se pueden describir en función de las otras y el conjunto minimal de observables necesarios para describir todas las propiedades del sistema se conoce como conjunto irreducible de observables (CIO) u observables fundamentales (OF). El conjunto de medidas realizadas sobre el CIO puede ser representado como coordenadas de un espacio vectorial, al cual llamaremos espacio de estado; de manera que los estados del sistema serán caracterizados a partir de puntos en dicho espacio.

En la QM, a todo sistema físico se le hace corresponder un espacio de Hilbert $\mathcal{H}$, complejo y separable. A cada observable $\mathcal{A}$ del sistema le corresponde un operador hermítico $\hat{A}$, cuyos autovalores son los valores que pueden resultar de una medida de $\mathcal{A}$. No todos los operadores hermíticos corresponden a un observable, pero el recíproco sí es cierto. En partícular, es de interés el Hamiltoniano $\hat{H}$, el cual es el operador asociado a la energía del sistema.

La notación bra-ket es la notación estándar en la QM para describir estados cuánticos. Un ket $\ket{\psi}$ representa un vector único asociado al estado $\psi$. En la representación matricial, un ket es un vector columna unitario. Un uso de los kets $\ket{i}$ es representar vectores con una única entrada no nula e igual a 1, en la posición $i+1$. Es importante resaltar que los kets son más generales que los vectores columna y que no necesariamente tienen esta representación, por ejemplo, en el caso en el que $\psi$ representa una variable continua. En el caso de la computación cuántica, se utilizan los kets $\ket{0}$ y $\ket{1}$ para describir los qubits en la base computacional. Este par de estados sería el equivalente a los bits 0 y 1 en la computación clásica. En su representación matricial, los kets $\ket{0}$ y $\ket{1}$ se representan de la siguiente manera:

\[\ket{0} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\]

\[\ket{1} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\]

Un bra es transpuesto hermítico de un ket. Los bras de la base computacional son $\bra{0}$ y $\bra{1}$. En la representación matricial estos son la transpuesta conjugada de los kets y se representan de la siguiente manera:

\[\bra{0} = \begin{pmatrix} 1 & 0 \end{pmatrix}\]

\[\bra{1} = \begin{pmatrix} 0 & 1 \end{pmatrix}\]

El producto interno de kets es el producto de un bra seguido de un ket $\braket{\phi}{\psi}$, el resultado de este producto es un número complejo y cumple las siguientes propiedades:

\begin{align}
    \braket{\phi}{\psi} &= z \\
    (\braket{\phi}{\psi})^\dagger &= \braket{\psi}{\phi} = z^*
\end{align}

El producto externo es el producto de un ket seguido de un bra $\ketbra{\phi}{\psi}$. El resultado es un proyector que toma la componente en $\ket{\psi}$ de un estado cuántico y la convierte en $\ket{\phi}$. Ejemplos:

\begin{align*}
    \ketbra{0}{0} &= \begin{pmatrix} 1 \\ 0 \end{pmatrix} \begin{pmatrix} 1 & 0 \end{pmatrix} = \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} \\
    \ketbra{0}{1} &= \begin{pmatrix} 1 \\ 0 \end{pmatrix} \begin{pmatrix} 0 & 1 \end{pmatrix} = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \\
    \ketbra{1}{0} &= \begin{pmatrix} 0 \\ 1 \end{pmatrix} \begin{pmatrix} 1 & 0 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix} \\
    \ketbra{1}{1} &= \begin{pmatrix} 0 \\ 1 \end{pmatrix} \begin{pmatrix} 0 & 1 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix} \\
    \ketbra{\psi}{\psi} &= (\alpha \ket{0} + \beta \ket{1})(\alpha^* \bra{0} + \beta^* \bra{1}) = \begin{pmatrix} \abs{\alpha}^2 & \alpha \beta^* \\ \alpha^* \beta & \abs{\beta}^2 \end{pmatrix}
\end{align*}

Este producto cumple con las siguientes propiedades:

\begin{align}
    \ketbra{\phi}{\psi} &= \hat{\Pi} \\
    (\ketbra{\phi}{\psi})^\dagger &= \ketbra{\psi}{\phi} = \hat{\Pi}^\dagger
\end{align}

El operador $\hat{\Pi}$ que consiste de un producto exterior se conoce como proyector. La aplicación de un proyector $\ketbra{\psi}{\phi}$ sobre un estado $\ket{\varphi}$ es equivalente a la multiplicación del escalar $c = \braket{\phi}{\varphi}$ al estado $\psi$.

\begin{equation}
    \ketbra{\psi}{\phi} \ket{\varphi} = \braket{\phi}{\varphi} \ket{\psi} = c \ket{\psi}
\end{equation}

Si además, el proyector es tal que $\psi = \phi$, es decir: $\hat{\Pi} = \ketbra{\psi}{\psi}$, entonces se cumple también que:

\begin{align}
    \hat{\Pi}^2 &= \ketbra{\psi}{\psi} \ketbra{\psi}{\psi} = 1 \ketbra{\psi}{\psi} = \hat{\Pi} \\
    \hat{\Pi}^\dagger &= (\ketbra{\psi}{\psi})^\dagger = \ketbra{\psi}{\psi} = \hat{\Pi}
\end{align}

La notación de Dirac se relaciona con el formalismo de funciones de onda de la siguiente manera:

\begin{equation}
    \psi(x, t) = \braket{x}{\psi(t)}
\end{equation}

Donde $\bra{x}$ es el bra asociado a alguna variable del sistema, usualmente posición o momenum.

Los ensambles estadísticas de estados cuánticos también son estados cuánticos. Esto nos lleva a distinguir entre estados puros y estados mixtos o mezcla. Los estados puros son los que podemos representar en la notación de bra-kets de Dirac, mientras que los estados mezcla se suelen representar en la notación de matrices u operadores densidad. Un estado puro, descrito por un ket $\ket{\psi}$, tiene la siguiente matriz densidad:

\begin{equation}
    \rho = \ketbra{\psi}{\psi}
\end{equation}

Por otro lado, si tenemos un ensamble $\{\ket{\psi_i}\}$, el estado mixto tiene la siguiente matriz densidad:

\begin{equation}
    \rho = \sum_i p_i \ketbra{\psi_i}{\psi_i}
\end{equation}

Donde $p_i$ es la probabilidad asociada a cada estado puro de la mezcla y $\sum_i p_i = 1$.

Las matrices densidad tienen las siguientes propiedades:

\begin{enumerate}
    \item Traza igual a uno: $Tr(\rho) = 1$
    \item Hermíticas: $\rho^\dagger = \rho$
    \item Autovalores no negativos: $\rho \ket{\lambda_i} = \lambda_i \ket{\lambda_i}, \quad \lambda_i \geq 0$
\end{enumerate}

Las matrices densidad asociadas a un estado puro, o mixto, se pueden intentificar con la traza del cuadrado de la matriz densidad:

\begin{enumerate}
    \item Estado puro: $Tr(\rho^2) = 1$
    \item Estado mixto $Tr(\rho^2) < 1$
\end{enumerate}

En una matriz densidad, los elementos de la diagonal son las poblaciones y los elementos fuera de ésta son las transiciones. Las poblaciones representan la probabilidades de que el sistema se encuentre en cada estado de la base tras una medida, mientras que las transiciones hacen referencia a la coherencia cuántica entre los elementos de la base que conforman el estado. Por ejemplo, el estado con superposición cuántica: $\ket{\psi} = (\ket{0} + \ket{1})/\sqrt{2}$ tiene la siguiente matriz densidad:

\begin{equation}
    \rho_1 = \ketbra{\psi}{\psi} = \frac{1}{2} (\ketbra{0}{0} + \ketbra{0}{1} + \ketbra{1}{0} + \ketbra{1}{1}) =
    \begin{pmatrix}
        \frac{1}{2} & \frac{1}{2} \\
        \frac{1}{2} & \frac{1}{2}
    \end{pmatrix}
\end{equation}

Mientras que el estado de mezcla clásica $\rho = (\rho_0 + \rho_1)/2$ tiene la siguiente matriz de probabilidad:

\begin{equation}
    \rho_2 = \frac{1}{2} (\ketbra{0}{0} + \ketbra{1}{1}) =
    \begin{pmatrix}
        \frac{1}{2} & 0 \\
        0 & \frac{1}{2}
    \end{pmatrix}
\end{equation}

Como se puede ver, ambos estados tienen probabilidad $1/2$ de encontrarse en $\ket{0}$ o en $\ket{1}$ que son los estados de la base. Sin embargo, en el primer estado, esto se debe a que es un único estado cuántico con superposición coherente. Mientras que en el segundo estado esto se debe a que es un estado mezcla de dos estados cuánticos, es decoherente. Este es un buen momento para notar la diferencia entre un estado mixto y estado coherente, pues un estado mezcla también puede ser coherente.

Tomemos los mismos estados $\rho_1$ y $\rho_2$ anteriores y construyamos el estado

\begin{equation}
    \rho = \frac{1}{2} (\rho_1 + \rho_2) =
    \begin{pmatrix}
        \frac{1}{2} & \frac{1}{4} \\
        \frac{1}{4} & \frac{1}{2}
    \end{pmatrix}
\end{equation}

Este es un estado mezcla, pero aún así tiene elementos fuera de la diagonal, los cuales indican coherencia. Es decir, este estado tiene componente de superposición cuántica, además de la mezcla clásica.

La evolución de los estados puros está dada por la ecuación de Schrödinger 

\begin{equation}
    i \hbar \frac{d}{dt} \ket{\psi(t)} = \hat{H} \ket{\psi(t)}
\end{equation}

Donde $i$ es la unidad imaginaria $\sqrt{-1}$, $\hbar$ es la constante de Planck reducida $h/2\pi$ y $\hat{H}$ es el Hamiltoniano del sistema. La generalización de la ecuación de Schrödinger para estados puros y mixtos es la ecuación de Liouville-von Neumann.

\begin{equation}
    i \hbar \dot{\rho}(t) = [\hat{H}, \rho(t)]
\end{equation}

La QM es una teoría probabilística. Los vectores de estado se construyen con amplitudes complejas de probabilidad asociadas a cada elemento de la base del espacio de Hilbert $\mathcal{H}$, y las matrices densidad a partir de probabilidades asociadas a cada estado que compone la mezcla. En la QM, una partícula puede encontrarse en cualquier parte del universo, en cualquier momento con, con cualquier energía, de acuerdo a cierta distribución de probabilidad. Sea $\ket{u}$ un autoestado del operador hermítico, asociado a un observable $\mathcal{A}$. Entonces, la función de distribución de probabilidad de $\mathcal{A}$ asociada al estado $\ket{\psi}$ es la siguiente:

\begin{equation}
    f_\mathcal{A}(u) = \abs{\braket{u}{\psi}}^2
\end{equation}

Esto es, el módulo al cuadrado de la proyección de $\ket{\psi}$ en $\ket{u}$. De hecho, debido a esto es que los estados cuánticos deben estar normalizados.

\begin{align}
    \abs{\braket{\psi}}^2 &= 1 \\
    \sum\limits \abs{\braket{\psi_i}{\psi}}^2 &= 1
\end{align}

Donde la suma es sobre los estados de alguna base de $\mathcal{H}$. En los formalismos de matriz de densidad y de función de onda, la normalización se escribe de las siguientes maneras:

\begin{align}
    Tr(\rho) &= 1 \\
    \int_S \abs{\psi(r,t)}^2 d^3 r &= 1
\end{align}

El valor esperado $\langle \mathcal{A} \rangle$ del mismo observable $\mathcal{A}$, en función del ket, la base de $\mathcal{H}$, la matriz densidad y la función de onda, es el siguiente:

\begin{align}
    \langle \mathcal{A} \rangle &= \bra{\psi} \hat{A} \ket{\psi} \\
    \langle \mathcal{A} \rangle &= \sum\limits_i \bra{\psi_i} \hat{A} \ket{\psi_i} \\
    \langle \mathcal{A} \rangle &= Tr(\hat{A} \rho)
\end{align}

\section{Sistemas multipartitos}

Cuando un sistema compuesto por dos (o más) espacios de Hilbert, $\mathcal{H}_A$ y $\mathcal{H}_B$, el espacio del sistema completo se escribe en función del producto tensorial $\mathcal{H} = \mathcal{H}_A \otimes \mathcal{H}_B$. Aquí, $\mathcal{H}_A$ y $\mathcal{H}_B$ se conocen como las particiones de $\mathcal{H}$. De igual manera, para representar un estado de $\mathcal{H}$ en un ket, en lugar de dos, se realiza el producto tensorial $\ket{\psi} = \ket{\psi_1} \otimes \ket{\psi_2}$. También se pueden agregar subindices a los kets para hacer énfasis en las particiones:

\begin{equation}
    \begin{array}{c c}
        \ket{\psi} & \in \mathcal{H} \\
        \ket{\psi}_A \otimes \ket{\phi}_B & \in \mathcal{H}_A \otimes \mathcal{H}_B \\
        \ket{\psi_1}_1 \otimes \ket{\psi_2}_2 \otimes ... \otimes \ket{\psi_n}_n & \in \mathcal{H}_1 \otimes \mathcal{H}_2 \otimes ... \otimes \mathcal{H}_n
    \end{array}
\end{equation}

En la representación matricial el producto tensorial se realiza de la siguiente manera:

\begin{equation*}
    \ket{\psi_1} \otimes \ket{\psi_2} =
    \begin{pmatrix}
        a \\
        b
    \end{pmatrix}
    \otimes
    \begin{pmatrix}
        c \\
        d
    \end{pmatrix}
    =
    \left(\!\!\!\begin{array}{c}
            a \left(\!\!\begin{array}{c}
                    c \\
                    d \\
            \end{array}\!\!\right) \\
            b \left(\!\!\begin{array}{c}
                    c \\
                    d \\
            \end{array}\!\!\right)
    \end{array}\!\!\!\right)
    =
    \begin{pmatrix}
        a c \\
        a d \\
        b c \\
        b d \\
    \end{pmatrix}
\end{equation*}

El producto tensorial tiene las siguientes propiedades:

\begin{align}
    (U_1 \otimes U_2) (\ket{\psi_1} \otimes \ket{\psi_2}) &= (U_1 \ket{\psi_1}) \otimes (U_2 \ket{\psi_2}) \\
    \ket{\psi_1} \otimes \ket{\psi_2} &\neq \ket{\psi_2} \otimes \ket{\psi_1} \\
    \alpha (\ket{\psi_1} \otimes \ket{\psi_2}) &= (\alpha \ket{\psi_1}) \otimes \ket{\psi_2} = \ket{\psi_1} \otimes (\alpha \ket{\psi_2}) \\
    (\ket{\psi_1} \otimes \ket{\psi_2})^\dagger &= \bra{\psi_1} \otimes \bra{\psi_2}
\end{align}

En el caso de los bras y los kets, el producto tensorial también se puede escribir de la forma $\ket{\psi\phi}$, en lugar de $\ket{\psi} \otimes \ket{\phi}$.

%Un estado multipartito se puede escribir de la forma extensa $\ket{\psi} \otimes \ket{\phi}$ o de la forma compacta $\ket{\psi \phi}$. También se pueden agregar subíndices para hacer énfasis en las particiones $\ket{\psi}_A \otimes \ket{\phi}$. Entonces:

\begin{equation*}
    \ket{\psi}_A \otimes \ket{\phi}_B = \ket{\psi} \otimes \ket{\phi} = \ket{\psi_A \phi_B} = \ket{\psi\phi}
\end{equation*}

Ejemplos:

\begin{equation*}
    \ket{0} \otimes \ket{0}
    = \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 1\\0 \end{pmatrix}
    = \begin{pmatrix} 1\\0\\0\\0 \end{pmatrix}
\end{equation*}

\begin{equation*}
    \ket{0} \otimes \ket{1}
    = \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix}
    = \begin{pmatrix} 0\\1\\0\\0 \end{pmatrix}
\end{equation*}

\begin{equation*}
    \ket{1} \otimes \ket{0}
    = \begin{pmatrix} 0\\1 \end{pmatrix} \otimes \begin{pmatrix} 1\\0 \end{pmatrix}
    = \begin{pmatrix} 0\\0\\1\\0 \end{pmatrix}
\end{equation*}

\begin{equation*}
    \ket{1} \otimes \ket{1}
    = \begin{pmatrix} 0\\1 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix}
    = \begin{pmatrix} 0\\0\\0\\1 \end{pmatrix}
\end{equation*}

\begin{equation*}
    \mathds{1} \otimes \sigma_x
    = \begin{pmatrix}
        1 & 0 \\
        0 & 1
        \end{pmatrix} \otimes
        \begin{pmatrix}
            0 & 1 \\
            1 & 0
        \end{pmatrix}
    = \begin{pmatrix}
        0 & 1 & 0 & 0 \\
        1 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 \\
        0 & 0 & 1 & 0
    \end{pmatrix}
\end{equation*}

La operación inversa del producto tensorial, para obtener $\mathcal{H}_A$ o $\mathcal{H}_B$ a partir de $\mathcal{H}$, es la traza parcial.

La traza parcial se define de la siguiente manera:

\begin{equation}
    Tr_A(\rho_{A B}) = \sum\limits_i (_A\bra{i} \otimes \mathds{1}_B) \rho (\ket{i}_A \otimes \mathds{1}_B)
\end{equation}

Esta traza elimina la porción de $\rho_{A B}$ perteneciente a $\mathcal{H}_A$. Si pudiesemos escribir $\rho_{A B} = \rho_A \otimes \rho_B$, entonces $Tr_A(\rho_{A B}) = \rho_B$

En caso que se quiera tener $\rho_A$ en lugar de $\rho_B$, entonces tenemos que tomar la traza parcial de la partición B, en lugar de la partición A, de la siguiente manera:

\begin{equation}
    Tr_B(\rho_{A B}) = \sum\limits_i (\mathds{1}_A \otimes _B\bra{i}) \rho (\mathds{1}_A \otimes \ket{i}_B)
\end{equation}

Para entender mejor la traza parcial, recordemos la definición de la traza normal:

\begin{equation}
    Tr(\rho) = \sum\limits_i \bra{i} \rho \ket{i}
\end{equation}

El par $\bra{i} \ket{i}$ lo que hace es seleccionar el i-ésimo elemento de la diagonal de la matriz $\rho$, entonces es la suma de todas las poblaciones en cada estado $\ket{i}$ de la base de $\mathcal{H}$ y mapea este espacio de Hilbert a uno escalar (en el caso de las matrices densidad, las mapea al número 1, por la normalización de las probabilidades). La traza parcial hace algo similar, solo que se aplica sobre la información de las particiones de $\mathcal{H}_A$ o de $\mathcal{H}_B$, dejando a la otra partición intacta. Es decir, el efecto de la traza y de las trazas parciales sobre una matriz densidad es, en resumen, el siguiente:

\begin{enumerate}
    \item $Tr(\rho_{A B}) = 1$, donde $\rho \in \mathcal{H}_A \otimes \mathcal{H}_B$
    \item $Tr_A(\rho_{A B}) = \rho_B$, donde $\rho \in \mathcal{H}_A \otimes \mathcal{H}_B$ y $\rho_B \in \mathcal{H}_B$
    \item $Tr_B(\rho_{A B}) = \rho_A$, donde $\rho \in \mathcal{H}_A \otimes \mathcal{H}_B$ y $\rho_A \in \mathcal{H}_A$
\end{enumerate}

Finalmente, comparemos algunos de los aspectos del producto tensorial y de la traza parcial.

\begin{enumerate}
    \item El producto tensorial se puede realizar con kets o con matrices densidad. Pero la traza parcial sólo se puede aplicar a matrices densidad.
    \item El producto tensorial de dos estados puros es otro estado puro. Sin embargo, las trazas parciales de un estado puro no necesariamente son estados puros. En la próxima sección se explicará más al respecto.
\end{enumerate}

\section{Postulados de la mecánica cuántica}

La QM que fundamenta la teoría de información cuántica se describe formalmente con los siguientes postulados desarrollados por la escuela de Copenhague a lo largo de todo el siglo XX \cite{Galindo_1990}.

\begin{enumerate}
    \item La descripción de un sistema físico en QM está dada en términos de los elementos de un espacio de Hilbert complejo separable asociado al sistema físico. En cada instante de tiempo $t$, un estado puro del sistema se representa por el vector unitario $\ket{\psi(t)}$ en el espacio de Hilbert correspondiente. Tal vector se llama vector de estado o ket.
    \item Todo observable de un sistema físico está representado en el formalismo de QM por un operador lineal hermítico el cual actúa en el espacio de Hilbert asociado con el sistema físico en consideración.
    \item Si un sistema físico está en un estado descrito por un vector normalizado $\ket{\psi}$ o una matriz densidad $\rho$, la probabilidad de obtener un valor $\lambda$ al medir un observable $\mathcal{A}$ está dada por 
        
        \begin{align}
            p(\lambda) &= \sum\limits_i^{g_n} \abs{\braket{\lambda_i}{\psi}}^2 \\
            p(\lambda) &= Tr(\Pi_\lambda \rho)
        \end{align}

        Donde $g_n$ es el grado de degeneración de $\hat{A}$ en $\lambda$, es decir, la cantidad de autoestados asociados a este mismo autovalores, $\ket{\lambda_i}$ son los autoestados asociados a $\lambda$ y el proyector $\Pi_\lambda$ es $\Pi_\lambda = \sum_i^{g_n} \ketbra{\lambda_i}$.

    \item Si un sistema físico está en el estado $\ket{\psi}$ o $\rho$, el estado resultante luego de una medida ideal del observable $\mathcal{A}$ está dado por

        \begin{align}
            \ket{\psi} &\rightarrow \frac{\Pi_\lambda \ket{\psi}}{\sqrt{\bra{\psi} \Pi_\lambda \ket{\psi}}} \\
            p(\lambda) &\rightarrow \frac{\mathcal{E}_\lambda(\rho)}{Tr(\Pi_\lambda \rho)}
        \end{align}

        Donde el mapa $\mathcal{E}_\lambda(\rho) = \sum_i^{g_n} \ketbra{\lambda_i} \rho \ketbra{\lambda_i}$.

    \item En un intervalo de tiempo entre dos medidas consecutivas, los estados puros de un sistema continuan siendo puros, y existen kets $\ket{\psi(t)}$ tales qeu la evolución del estado del sistema está dada por la ecuación de Schrödinger

        \begin{equation}
            i \hbar \frac{d}{dt} \ket{\psi(t)} = \hat{H}(t) \ket{\psi(t)}
        \end{equation}

        Donde $\hat{H}(t)$ es un observable llamado Hamiltoniano, el cual representa la energía del sistema. Los obervables del sistema se representan por operadores que son constantes en el tiempo, a menos que los dispositivos de medida cambien en el tiempo, en tal caso, los operadores deberán contener dichos cambios.
    \item Para un sistema físico en el cual las coordenadas cartesianas son $q_1, q_2, ... , q_N$, con los correspondientes momenta conjugados $p_1, p_2, ... , p_N$, los operadores $X$ y $P$, los cuales representan estos observables en QM, deben satisfacer las relaciones de conmutación

        \begin{equation}
            [X_r, X_a] = 0, [P_r, P_a] = 0, [X_r, P_a] = i \hbar \delta_{ra}
        \end{equation}

        Si el sistema tiene un observable cuya expresión clásica es $A(q_1, ... , q_N, p_1, ... , p_N; t)$, la aplicación usual en QM del operador correspondiente se obtiene sustituyendo las variables $q_r$ y $p_a$ por los operadores $X_r$ y $P_a$, respectivamente.
\end{enumerate}

\section{Entrelazamiento}

Consideremos el estado $\ket{\psi} = (\ket{00} + \ket{11})/\sqrt{2}$ e intentemos escribirlo en función de $\ket{\psi_1}$ y $\ket{\psi_2}$, tal que $\ket{\psi} = \ket{\psi_1} \otimes \ket{\psi_2}$.

\begin{align*}
    \ket{\psi}
    &= (\alpha \ket{0} + \beta \ket{1}) \otimes (\gamma \ket{0} + \delta \ket{1}) \\
    &= \alpha \gamma \ket{00} + \alpha \delta \ket{01} + \beta \gamma \ket{10} + \beta \delta \ket{11}
\end{align*}

De aquí se debe cumplir que:

$$
    \alpha \gamma = \frac{1}{\sqrt{2}} \qquad
    \alpha \delta = 0 \qquad
    \beta \gamma = 0 \qquad
    \beta \delta = \frac{1}{\sqrt{2}} \qquad
$$

Pero esto implicaría, al mismo tiempo que:

\begin{enumerate}
    \item Al menos una variable de cada uno de los siguientes pares de variables es cero: $\{\alpha, \delta\}$ y $\{\beta, \gamma\}$
    \item Ninguna de las siguientes variables es cero: $\alpha, \beta, \gamma, \delta$
\end{enumerate}

Lo cual resulta contradictorio y se concluye que existen estados no separables. Veamos qué significa esto en términos de la distribución de probabilidaes:

\[
\begin{array}{c c c c}
    & \ket{\psi}_A = \ket{0} & \ket{\psi}_A = \ket{0} & P(A) \\
    \ket{\psi}_B = \ket{0} & 1/2 & 0 & 1/2 \\
    \ket{\psi}_B = \ket{1} & 0 & 1/2 & 1/2 \\
    P(B) & 1/2 & 1/2 &
\end{array}
\]

De esta tabla se puede ver que las particiones $A$ y $B$ no son independientes, pues las probabilidades condicionadas no son el producto de las probabilidades sin condicionar $P(A|B) \neq P(A)P(B)$. Es decir, existe una correlación.

A la correlación que causa la inseparabilidad de los sistemas se le conoce como entrelazamiento y es la correlación cuántica que va más allá de la interacción espacial.

Si se toma la traza parcial de un estado enterlazado puro, el resultado es un estado mixto, como consecuencia de la inseparabilidad de los estados entrelazados.

De aquí surge la siguiente clasificación de los estados cuánticos:

\color{red}
\begin{enumerate}
    \item Estado producto: $\rho = \rho_A \otimes \rho_B$
    \item Estado separable: $\rho = \sum\limits_{i j} p_{i j} (\rho_{A_i} \otimes \rho_{B_j})$
    \item Estado entrelazado: $\rho \neq \sum\limits_{i j} p_{i j} (\rho_{A_i} \otimes \rho_{B_j})$
\end{enumerate}
\color{black}

\section{Qubits}
Un qubit es un sistema físico de dos niveles, es decir, es un objeto cuyo estado es un elemento del espacio de Hilbert de dimensión $\dim (\mathcal{H})=2$ y puede ser escrito de la siguiente manera: $ \ket{\psi} = \alpha \ket{0} + \beta \ket{1} $, donde $ \{ \ket{0},\ket{1} \} $ forma una base de $\mathcal{H}$ y donde $ \alpha $ y $ \beta $ son números complejos, tales que $ | \alpha |^2 + | \beta |^2 = 1 $, conocidos como amplitudes de probabilidad.

El qubit se puede pensar como el equivalente en IC del bit, el cual, por sus propiedad cuánticas, puede estar no sólo puede estar en el estado $\ket{0}$ y en el estado $\ket{1}$, sino también en superposiciones de estos dos.

\section{Esfera de Bloch}

El estado de un qubit también se puede escribir de la siguiente manera: $ \ket{\psi} = e^{i \phi_0} \cos ( \theta ) \ket{0} + e^{i \phi_1} \sin ( \theta ) \ket{1}  = e^{i \phi_0} (\cos ( \theta ) \ket{0} + e^{i ( \phi1 - \phi_0 )} \sin ( \theta ) \ket{1}) $, donde $ \theta $, $\phi_0$ y $\phi_1$ son números reales. La fase global $\phi_0$ es ignorable, pues no tiene ningún efecto sobre las probabilidades. Entonces, sin pérdida de generalidad, $ \ket{\psi} = \cos ( \theta ) \ket{0} + \sin ( \theta ) e^{i \phi} \ket{1} $, donde $ \theta \in [0, \pi ] $ y $ \phi \in [0, 2 \pi ] $. De esta manera, podemos representar los qubits en una esfera unitaria, conocida como esfera de Bloch. En esta esfera el ket $\ket{0}$ corresponde al vector (0,0,1), mientras que el ket $\ket{1}$ corresponde al vector (0,0,-1).

Todas las operaciones de un qubit se pueden ver como rotaciones en la esfera de Bloch. Por ejemplo, un \textit{bit-flip} sería una rotación de $\pi$ sobre el eje X, tal que $(0,0,1) \rightarrow (0,0,-1)$, es decir $\ket{0} \rightarrow \ket{1}$.

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=3cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis{0}{0}
        \drawAxis{90}{0}
        \drawAxis{90}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \labelLatLon{up}{90}{0};
        \labelLatLon{down}{-90}{90};
        \node[above] at (up) {{\tiny $\hat{z} = \ket{0}$ }};
        \node[below] at (down) {{\tiny $-\hat{z} = \ket{1}$}};

        \labelLatLon{yp}{0}{0};
        \labelLatLon{ym}{0}{180};
        \node[right] at (yp) {{\tiny $\hat{y} = \ket{\circlearrowleft} = \frac{\ket{0} + i \ket{1}}{\sqrt{2}}$ }};
        \node[left] at (ym) {{\tiny $-\hat{y} = \ket{\circlearrowright} = \frac{\ket{0} - i \ket{1}}{\sqrt{2}}$ }};

        \labelLatLon{xp}{0}{90};
        \labelLatLon{xm}{0}{-90};
        \node[below] at (xp) {{\tiny $\hat{x} = \ket{+} = \frac{\ket{0} + \ket{1}}{\sqrt{2}}$ }};
        \node[above] at (xm) {{\tiny $-\hat{x} = \ket{-} = \frac{\ket{0} - \ket{1}}{\sqrt{2}}$ }};

        \drawStateLatLon{psi}{20}{40}
        \node[right] at (psi) {{\tiny $\ket{\psi}$ }};
    \end{blochsphere}
    \caption{Esfera de Bloch}
    \label{fig:bloch}
\end{figure}



\section{Matrices de Pauli}

Estas matrices son de especial importancia en la QM y representan el spin de una partícula. Ellas son:

\begin{align}
    \sigma_x &=
        \begin{pmatrix}
            0 & 1 \\
            1 & 0
        \end{pmatrix} \\
    \sigma_y &=
        \begin{pmatrix}
            0 & -i \\
            i & 0
        \end{pmatrix} \\
    \sigma_z &=
        \begin{pmatrix}
            1 & 0 \\
            0 & -1
        \end{pmatrix}
\end{align}

Las matrices de Pauli cumplen las siguientes propiedades:

\begin{enumerate}
    \item Autovalores $\pm 1$
    \item Hermiticas
    \item $[\sigma_i, \sigma_j] = i \sigma_k$, donde $(i,j) \in \{(x,y), (y,z), (z,x)\}$
    \item $[\sigma_j, \sigma_i] = - i \sigma_k$, donde $(i,j) \in \{(x,y), (y,z), (z,x)\}$
\end{enumerate}

\section{Circuitos cuánticos}

El equivalente a los circuitos digitales en la computación cuántica es los circuitos cuánticos. Ellos describen la secuencia de operaciones que se deben aplicar a los qubits para ejecutar cierto algoritmo. Esas operaciones pueden ser transformaciones unitarias, conocidas como compuertas cuánticas, o medidas proyectivas. Es importante resaltar que estos circuitos no representan componentes tangibles, sino componentes de información. De esta manera, las compuertas cuánticas no son componentes electrónicos de ninguna manera, sólo representan las transformaciones que se aplican a los qubits. En este sentido, los circuitos cuánticos son más el análogo del lenguaje de máquina que de los circuitos digitales. En general, las compuertas cuánticas se implementan con distintos tipo de ondas y pulsos electromagnéticos.

\[
    \Qcircuit @C=1.4em @R=1.8em {
        \lstick{\ket{0}} & \gate{U}  & \ctrl{2} & \qw        & \gate{U}   & \qw & \qw    \\
        \lstick{\ket{0}} & \multigate{1}{U} & \qw      & \ctrlo{1}  & \ctrl{-1}  & \qw & \qw    \\
        \lstick{\ket{1}} & \ghost{U} & \gate{U} & \gate{U}   & \ctrlo{-1} & \meter & \cw \\
    }
\]

En esta figura se observan los siguientes elementos:

\begin{enumerate}
    \item Estado inicial: Este es el estado con el que se inicia el algoritmo.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        \lstick{\ket{\psi}} \\
    }
\]
    \item Compuerta de un qubit: Representa una operación unitaria sobre el qubit en cuya linea se encuentra.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \gate{U} \\
    }
\]
    \item Compuerta multiqubit: Representa una operación unitaria sobre los qubits en cuyas líneas se encuentra.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \multigate{1}{U} \\
        & \ghost{U} \\
    }
\]
    \item Compuerta condicionada cuánticamente: El punto blanco o negro indica que el qubit de esa línea es el qubit de control. Si el punto es blanco, se aplica la compuerta $U$ si el qubit de control es $\ket{0}$. Si el punto es negro, se aplica la compuerta $U$ si el qubit de control es $\ket{1}$. Es caso de que el qubit de control se encuentre en estado de superposición, la compuerta se aplica y no se aplica, simultaneamente.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \ctrl{1} \\
        & \gate{U} \\
    }
\]
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \ctrlo{1} \\
        & \gate{U}  \\
    }
\]
    \item Compuerta condicionada clásicamente: Equivalente a un if de cualquier lenguaje de programación clásica. Sólo se aplica la compuerta $U$ si el bit de control es 1.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \cwx[1] \\
        & \gate{U}  \\
    }
\]
    \item Medida proyectiva: Representa una medida proyectiva del qubit en cuya linea se encuentra.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \meter \\
    }
\]
    \item Cable cuántico: No es un cable físico, sólo lleva ese nombre en analogía a los circuitos clásicas, donde las compuertas sí son componentes electrónicos en conexión. En el caso de los circuitos cuánticos, este elemento sólo representa que se mantiene la coherencia del qubit y que no se aplica ninguna compuerta sobre él en ese paso del algoritmo.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \qw \\
    }
\]
    \item Cable clásico: Representa el bit clásico que se obtiene tras la medida de un qubit.
\[
    \Qcircuit @C=1.4em @R=1.8em {
        & \cw \\
    }
\]
\end{enumerate}

Las compuertas cuánticas difieren de las compuertas clásicas en que las primeras son reversibles. Esto implica que una compuerta cuántica siempre tiene la misma cantidad de entradas que de salidas y que conociendo la compuerta y la salida, se puede conocer inequívocamente la entrada. Este no es el caso con las compuertas clásicas. Por ejemplo, una compuerta AND tiene dos entradas, pero una sóla salida y no hay manera de conocer la entrada si la salida es 0. De hecho, incluso si se extiende la compuerta AND para incluir una de las entradas como una segunda salida, de manera de tener la misma cantidad de salidas que de entradas, como es el caso con las compuertas cuánticas, sigue siendo imposible conocer la otra entrada si ambas salidas son 0.

Otra diferencia está en la variedad de compuertas que pueden existir. Como ejemplo, consideremos las compuertas de una entrada y una salida. En el caso clásico, sólo existen dos compuertas: el buffer y el NOT. Mientras que en el caso cuántico, existen infinitas compuertas de un qubit, pues cualquier elemento de SU(2) puede ser una compuerta.

\section{Compuertas cuánticas de un qubit}
Las operaciones unitarias con las que se opera sobre los qubits reciben el nombre de compuertas cuánticas.

Las compuertas de un sólo qubit pueden ser vistas como rotaciones en la esfera de Bloch.

\subsection{Compuerta identidad}

Esta operación es equivalente a \textit{no-operation} en una computadora clásica.

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \gate{I} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    I = 
    \begin{pmatrix}
    1 & 0 \\
    0 & 1
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $\ket{0}$ \\
    $\ket{1}$ & $\ket{1}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $\alpha \ket{0} + \beta \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis{0}{0}
        \drawAxis{90}{0}
        \drawAxis{90}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \drawStateLatLon[statecolor=red]{psi1}{33}{45}
        \drawStateLatLon[statecolor=blue]{psi2}{33}{45}
        \node[left] at (psi1) {{\tiny $\ket{\psi_i}$ }};
        \node[right] at (psi2) {{\tiny $\ket{\psi_f}$ }};
    \end{blochsphere}
    \caption{Compuerta I en la esfera de Bloch}
    \label{fig:blochid}
\end{figure}

\subsection{Compuerta X}
Este es el equivalente al NOT clásico, pues tránsforma los $\ket{0}$ en $\ket{1}$ y viceversa, ya que realiza una rotación de $\pi$ sobre el eje X en la esfera de Bloch. Su forma matricial viene dada por la matriz de Pauli $\sigma_x$

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \gate{X} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    X =
    \begin{pmatrix}
    0 & 1 \\
    1 & 0
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $\ket{1}$ \\
    $\ket{1}$ & $\ket{0}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $\beta \ket{0} + \alpha \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis{0}{0}
        \drawAxis[style={green}]{90}{0}
        \drawAxis{90}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \drawStateLatLon[statecolor=red]{psi1}{75}{0}
        \drawStateLatLon[statecolor=blue]{psi2}{255}{0}
        \node[right] at (psi1) {{\tiny $\ket{\psi_i}$ }};
        \node[left] at (psi2) {{\tiny $\ket{\psi_f}$ }};
    \end{blochsphere}
    \caption{Compuerta X en la esfera de Bloch}
    \label{fig:blochx}
\end{figure}

\subsection{Compuerta Z}
Esta compuerta no tiene análogo clásico, pues lo que realiza es un cambio de fase de $\pi$. Esto equivale a una rotación de $\pi$ sobre el eje Z en la esfera de Bloch. Su forma matricial viene dada por la matriz de Pauli $\sigma_z$

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \gate{Z} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    Z =
    \begin{pmatrix}
    1 & 0 \\
    0 & -1
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $\ket{0}$ \\
    $\ket{1}$ & $-\ket{1}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $\alpha \ket{0} - \beta \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis[style={green}]{0}{0}
        \drawAxis{90}{0}
        \drawAxis{90}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \drawStateLatLon[statecolor=red]{psi1}{0}{-255}
        \drawStateLatLon[statecolor=blue]{psi2}{0}{-75}
        \node[left] at (psi1) {{\tiny $\ket{\psi_i}$ }};
        \node[right] at (psi2) {{\tiny $\ket{\psi_f}$ }};
    \end{blochsphere}
    \caption{Compuerta Z en la esfera de Bloch}
    \label{fig:blochz}
\end{figure}

\subsection{Compuerta Y}
Esta compuerta realiza una rotación de $\pi$ sobre el eje y de la esfera de Bloch. Distintos autores definen la forma matricial de esta compuerta de dos maneras distintas, una forma viene dada por la matriz de Pauli $\sigma_y$ y otra es esta matriz por una fase global de $i$.

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \gate{Y} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    Y =
    \begin{pmatrix}
    0 & -i \\
    i & 0
    \end{pmatrix}
\text{ ó }
    Y =
    \begin{pmatrix}
    0 & 1 \\
    -1 & 0
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $i \ket{1}$ ó $-\ket{1}$ \\
    $\ket{1}$ & $-i\ket{0}$ ó $\ket{0}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $-i \beta \ket{0} + i \alpha \ket{1}$ ó $\beta \ket{0} - \alpha \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis{0}{0}
        \drawAxis[style={green}]{90}{0}
        \drawAxis{90}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \drawStateLatLon[statecolor=red]{psi1}{75}{90}
        \drawStateLatLon[statecolor=blue]{psi2}{255}{90}
        \node[left] at (psi1) {{\tiny $\ket{\psi_i}$ }};
        \node[right] at (psi2) {{\tiny $\ket{\psi_f}$ }};
    \end{blochsphere}
    \caption{Compuerta Y en la esfera de Bloch}
    \label{fig:blochy}
\end{figure}

\subsection{Compuerta de Hadamard}
Esta compuerta transforma los estados de la base computacional $\ket{0}$ y $\ket{1}$ en estados de superposiciones uniformes ($\ket{+} = (\ket{0} + \ket{1})/\sqrt{2}$ y $\ket{-} = (\ket{0} - \ket{1})/\sqrt{2}$). También se puede interpretar como el mapa de la base Z a la base X. Ella consiste de una rotación de $\pi$ sobre el eje $(x+z)$ y se puede realizar con una rotación de $\pi/2$ sobre el eje Y seguida de la compuerta X.

\begin{minipage}{0.5\textwidth}
    \[
        \Qcircuit @C=1.4em @R=1.8em {
        & \gate{H} & \qw
        }
    \]
\end{minipage}
\begin{minipage}{0.5\textwidth}
    \[
        H = 
        \frac{1}{\sqrt{2}}
        \begin{pmatrix}
            1 & 1 \\
            1 & -1
        \end{pmatrix}
    \]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $\frac{\ket{0} + \ket{1}}{\sqrt{2}}$ \\
    $\ket{1}$ & $\frac{\ket{0} - \ket{1}}{\sqrt{2}}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $\frac{\alpha + \beta}{\sqrt{2}} \ket{0} + \frac{\alpha - \beta}{\sqrt{2}} \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis{0}{0}
        \drawAxis{90}{0}
        \drawAxis{90}{90}
        \drawAxis[style={green}]{45}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \drawStateLatLon[statecolor=red]{psi1}{90}{0}
        \drawStateLatLon[statecolor=blue]{psi2}{0}{90}
        \node[left] at (psi1) {{\tiny $\ket{\psi_i}$ }};
        \node[left] at (psi2) {{\tiny $\ket{\psi_f}$ }};
    \end{blochsphere}
    \caption{Compuerta H en la esfera de Bloch}
    \label{fig:blochh}
\end{figure}

\subsection{Compuerta S}
Esta compuerta es la raiz cuadrada de Z e introduce una fase de $\pi/2$ al qubit.

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \gate{S} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    S =
    \begin{pmatrix}
    1 & 0 \\
    0 & i
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $\ket{0}$ \\
    $\ket{1}$ & $i \ket{1}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $\alpha \ket{0} + i \beta \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis[style={green}]{0}{0}
        \drawAxis{90}{0}
        \drawAxis{90}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \drawStateLatLon[statecolor=red]{psi1}{0}{90}
        \drawStateLatLon[statecolor=blue]{psi2}{0}{0}
        \node[left] at (psi1) {{\tiny $\ket{\psi_i}$ }};
        \node[right] at (psi2) {{\tiny $\ket{\psi_f}$ }};
    \end{blochsphere}
    \caption{Compuerta S en la esfera de Bloch}
    \label{fig:blochs}
\end{figure}

\subsection{Compuerta T}
Esta compuerta es la raiz cuadrada de S e introduce una fase de $\pi/4$ al qubit.

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \gate{T} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    T =
    \begin{pmatrix}
    1 & 0 \\
    0 & e^{\frac{i \pi}{4}}
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $\ket{0}$ \\
    $\ket{1}$ & $e^{\frac{i \pi}{4}} \ket{1}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $\alpha \ket{0} + e^{\frac{i \pi}{4}} \beta \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis[style={green}]{0}{0}
        \drawAxis{90}{0}
        \drawAxis{90}{90}

        %\drawRotationRight[scale=1.3,style={red}]{-90}{0}{0}{15}

        \drawStateLatLon[statecolor=red]{psi1}{0}{90}
        \drawStateLatLon[statecolor=blue]{psi2}{0}{45}
        \node[left] at (psi1) {{\tiny $\ket{\psi_i}$ }};
        \node[right] at (psi2) {{\tiny $\ket{\psi_f}$ }};
    \end{blochsphere}
    \caption{Compuerta T en la esfera de Bloch}
    \label{fig:blocht}
\end{figure}

\subsection{Compuerta de cambio de fase}

Esta compuerta es similar a Z, S y T, sólo que introduce una fase $\phi$ cualquiera al qubit.

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \gate{P_{\phi}} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    P_\phi =
    \begin{pmatrix}
    1 & 0 \\
    0 & e^{i \phi}
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{0}$ & $\ket{0}$ \\
    $\ket{1}$ & $e^{i \phi} \ket{1}$ \\
    $\alpha \ket{0} + \beta \ket{1}$ & $\alpha \ket{0} + e^{i \phi} \beta \ket{1}$
\end{tabular}
\end{center}

\begin{figure}[H]
    \center
    \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
        \drawBallGrid[style={opacity=0.1}]{30}{30}

        \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
        \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
        \drawAxis[style={green}]{0}{0}
        \drawAxis{90}{0}
        \drawAxis{90}{90}

        \drawRotationRight[scale=1.3,style={red}]{0}{0}{0}{15}
    \end{blochsphere}
    \caption{Compuerta P en la esfera de Bloch}
    \label{fig:blochp}
\end{figure}

\subsection{Compuertas de rotación}

Una rotación general en la esfera de Bloch se escribe de la siguiente manera:

\[
R(\theta,\hat{r}) = e^{i \frac{\theta}{2} \vec{\sigma} \cdot \hat{r}} =
\begin{pmatrix}
\cos(\frac{\theta}{2}) + i z \sin(\frac{\theta}{2}) & \sin(\frac{\theta}{2}) (i x + y) \\
\sin(\frac{\theta}{2}) (i x - y) & \cos(\frac{\theta}{2}) - i z \sin(\frac{\theta}{2})
\end{pmatrix}
\]

Donde $\hat{r}$ es el vector unitario asociado al eje de la rotación, $\theta$ es el ángulo que se rota y $\vec{\sigma}$ es el vector de las matrices de Pauli $(\sigma_x, \sigma_y, \sigma_z)$.

Si $\hat{r} = (1,0,0)$, se tiene la rotación general sobre X.

\[
R_x(\theta) =
\begin{pmatrix}
\cos(\frac{\theta}{2}) & i \sin(\frac{\theta}{2}) \\
i\sin(\frac{\theta}{2}) & \cos(\frac{\theta}{2})
\end{pmatrix}
\]

Si $\hat{r} = (0,1,0)$, se tiene la rotación general sobre Y.

\[
R_y(\theta) =
\begin{pmatrix}
\cos(\frac{\theta}{2}) & \sin(\frac{\theta}{2}) \\
-\sin(\frac{\theta}{2}) & \cos(\frac{\theta}{2})
\end{pmatrix}
\]

Si $\hat{r} = (0,0,1)$, se tiene la rotación general sobre Z.

\[
R_z(\theta) =
\begin{pmatrix}
e^{i \frac{\theta}{2}} & 0 \\
0 & e^{-i \frac{\theta}{2}}
\end{pmatrix}
\]

\begin{figure}[H]
    \centering
    \begin{subfigure}[m]{0.32\textwidth}
    \centering
        \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
            \drawBallGrid[style={opacity=0.1}]{30}{30}

            \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
            \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
            \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
            \drawAxis{0}{0}
            \drawAxis{90}{0}
            \drawAxis[style={green}]{90}{90}

            \drawRotationRight[scale=1.3,style={red}]{90}{90}{0}{15}
        \end{blochsphere}
        \caption{Rx}
    \end{subfigure}
    \begin{subfigure}[m]{0.32\textwidth}
    \centering
        \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
            \drawBallGrid[style={opacity=0.1}]{30}{30}

            \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
            \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
            \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
            \drawAxis{0}{0}
            \drawAxis[style={green}]{90}{0}
            \drawAxis{90}{90}

            \drawRotationRight[scale=1.3,style={red}]{90}{0}{0}{15}
        \end{blochsphere}
        \caption{Ry}
    \end{subfigure}
    \begin{subfigure}[m]{0.32\textwidth}
        \centering
        \begin{blochsphere}[radius=1.5cm,tilt=15,rotation=-20,opacity=0.05]
            \drawBallGrid[style={opacity=0.1}]{30}{30}

            \drawGreatCircle[style={dashed,opacity=0.5}]{0}{0}{0}
            \drawGreatCircle[style={dashed,opacity=0.5}]{90}{0}{0}
            \drawGreatCircle[style={dashed,opacity=0.5}]{90}{90}{0}
            \drawAxis[style={green}]{0}{0}
            \drawAxis{90}{0}
            \drawAxis{90}{90}

            \drawRotationRight[scale=1.3,style={red}]{0}{0}{0}{15}
        \end{blochsphere}
        \caption{Rz}
    \end{subfigure}
    \caption{Compuertas Rx, Ry y Rz en la esfera de Bloch}
    \label{fig:blochr}
\end{figure}

Para realizar cualquier rotación en la esfera de Bloch, basta con poder realizar rotaciones generales sobre dos ejes ortogonales de ella. A partir de secuencias tres rotaciones alrededor de estos dos ejes se puede realizar cualquier rotación alrededor de cualquier otro eje. Por ejemplo, las rotaciones alrededor de X, en función de rotaciones alrededor de Y y Z se realizan de la siguiente manera:

\[
    R_x(\theta) = R_z(\frac{\pi}{2}) R_y(\theta) R_z(\frac{-\pi}{2})
\]

\section{Compuertas multiqubit}

Las compuertas multiqubit involucran interacción entre los qubits.

\subsection{Compuerta CNOT}

La compuerta CNOT, o \textit{controlled-NOT}, es un ejemplo de una compuerta condicionada. De hecho, es la compuerta X condicionada. Ella recibe dos qubits de entrada, un \textit{control} y un \textit{target}. Si el qubit de control es $\ket{0}$ se aplica $\mathds{1}$ sobre el qubit objetivo y si el qubit de control es $\ket{1}$, se aplica X sobre el qubit objetivo. Esta compuerta se puede escribir en función de proyectores en la partición del qubit de control de la siguiente manera: $\text{CNOT} =\Pi_0 \otimes \mathds{1} + \Pi_1 \otimes \text{X}$.

\begin{minipage}{0.5\textwidth}
\[
\Qcircuit @C=1.4em @R=1.8em {
& \ctrl{1} & \qw \\
& \targ & \qw \\
}
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    CNOT =
    \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 \\
    0 & 0 & 1 & 0
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{00}$ & $\ket{00}$ \\
    $\ket{01}$ & $\ket{01}$ \\
    $\ket{10}$ & $\ket{11}$ \\
    $\ket{11}$ & $\ket{10}$ \\
    $\alpha \ket{00} + \beta \ket{01} + \gamma \ket{10} + \delta \ket{11}$ & $\alpha \ket{00} + \beta \ket{01} + \delta \ket{10} + \gamma \ket{11}$
\end{tabular}
\end{center}

\subsection{Compuerta SWAP}

La compuerta SWAP, como su nombre lo indica, intercambia el contenido de dos particiones de qubits. Es decir, transforma $\ket{\psi} \otimes \ket{\phi}$ en $\ket{\phi} \otimes \ket{\psi}$.

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \qswap & \qw \\
    & \qswap \qwx & \qw \\
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    SWAP =
    \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{00}$ & $\ket{00}$ \\
    $\ket{01}$ & $\ket{10}$ \\
    $\ket{10}$ & $\ket{01}$ \\
    $\ket{11}$ & $\ket{11}$ \\
    $\alpha \ket{00} + \beta \ket{01} + \gamma \ket{10} + \delta \ket{11}$ & $\alpha \ket{00} + \gamma \ket{01} + \beta \ket{10} + \delta \ket{11}$
\end{tabular}
\end{center}

Si se tiene un sistema de qubits dividido en dos partes o registros del mismo tamaño, también se llama SWAP a la compuerta que intercambia estos dos registros. Es decir, a la operación que transforma $\ket{\psi_1} \otimes ... \otimes \ket{\psi_n} \otimes \ket{\phi_1} \otimes ... \otimes \ket{\phi_n}$ en $\ket{\phi_1} \otimes ... \otimes \ket{\phi_n} \otimes \ket{\psi_1} \otimes ... \otimes \ket{\psi_n}$. Ella se construye de la siguiente manera:

\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \qswap      & \qw & \qw         & \qw & \qw         & \qw & \qw         & \qw \\
    & \qw \qwx    & \qw & \qswap      & \qw & \qw         & \qw & \qw         & \qw \\
    & \qw \qwx    & \qw & \qw \qwx    & \qw & \qswap      & \qw & \qw         & \qw \\
    & \qw \qwx    & \qw & \qw \qwx    & \qw & \qw \qwx    & \qw & \qswap      & \qw \\
    & \qswap \qwx & \qw & \qw \qwx    & \qw & \qw \qwx    & \qw & \qw \qwx    & \qw \\
    & \qw         & \qw & \qswap \qwx & \qw & \qw \qwx    & \qw & \qw \qwx    & \qw \\
    & \qw         & \qw & \qw         & \qw & \qswap \qwx & \qw & \qw \qwx    & \qw \\
    & \qw         & \qw & \qw         & \qw & \qw         & \qw & \qswap \qwx & \qw \\
}
\]


\subsection{Compuerta $\sqrt{\text{SWAP}}$}

\begin{minipage}{0.5\textwidth}
\[
    \Qcircuit @C=1.4em @R=1.8em {
    & \qswap & \qw \\
    & \qswap\qwxo{\scalebox{0.5}{$1\hspace{-1pt}/\hspace{-1pt}2$}} & \qw
    }
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
    \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & \frac{1}{2} (1+i) & \frac{1}{2} (1-i) & 0 \\
    0 & \frac{1}{2} (1-i) & \frac{1}{2} (1+i) & 0 \\
    0 & 0 & 0 & 1
    \end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{00}$ & $\ket{00}$ \\
    $\ket{01}$ & $\frac{1+i}{2} \ket{01} + \frac{1-i}{2} \ket{10}$ \\
    $\ket{10}$ & $\frac{1-i}{2} \ket{01} + \frac{1+i}{2} \ket{10}$ \\
    $\ket{11}$ & $\ket{11}$ \\
    $\alpha \ket{00} + \beta \ket{01} + \gamma \ket{10} + \delta \ket{11}$ & $\alpha \ket{00} + (\frac{1+i}{2}\beta + \frac{1-i}{2}\gamma) \ket{01} + (\frac{1-i}{2}\beta + \frac{1+i}{2}\gamma) \ket{10} + \delta \ket{11}$
\end{tabular}
\end{center}

\subsection{Compuerta de Ising}

Esta compuerta es fundamental para las computadoras cuánticas a base de trampas de iones, pues se puede realizar de manera nativa en estos sistemas \cite{Wang_2010, Mkrtchian_2008}.

\begin{minipage}{0.5\textwidth}
\[
\Qcircuit @C=1.4em @R=1.8em {
& \multigate{1}{\mathit{XX}_{\phi}} & \qw \\
& \ghost{\mathit{XX}_{\phi}} & \qw
}
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
\frac{1}{\sqrt{2}}
\begin{pmatrix}
1 & 0 & 0 & -i e^{i \phi} \\
0 & 1 & -i & 0 \\
0 & -i & 1 & 0 \\
-i e^{-i \phi} & 0 & 0 & 1
\end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{00}$ & $\frac{1}{\sqrt{2}} (\ket{00} - i e^{-i \phi} \ket{11})$ \\
    $\ket{01}$ & $\frac{1}{\sqrt{2}} (\ket{01} - i \ket{10})$ \\
    $\ket{10}$ & $\frac{1}{\sqrt{2}} (- i \ket{01} + \ket{10})$ \\
    $\ket{11}$ & $\frac{1}{\sqrt{2}} (- i e^{i \phi} \ket{00} + \ket{11})$ \\
    $\alpha \ket{00} + \beta \ket{01} + \gamma \ket{10} + \delta \ket{11}$ & $\frac{\alpha - i e^{i \phi} \delta}{\sqrt{2}} \ket{00} + \frac{\beta - i \gamma}{\sqrt{2}} \ket{01} + \frac{\gamma - i \beta}{\sqrt{2}} \ket{10} + \frac{\delta - i e^{-i \phi} \alpha}{\sqrt{2}} \ket{11}$
\end{tabular}
\end{center}

\subsection{Compuerta de Toffoli}

\begin{minipage}{0.5\textwidth}
\[
\Qcircuit @C=1.4em @R=1.8em {
& \ctrl{1} & \qw \\
& \ctrl{1} & \qw \\
& \targ & \qw \\
}
\]
\end{minipage}
\begin{minipage}{0.5\textwidth}
\[
\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0
\end{pmatrix}
\]
\end{minipage}

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{000}$ & $\ket{000}$ \\
    $\ket{001}$ & $\ket{001}$ \\
    $\ket{010}$ & $\ket{010}$ \\
    $\ket{011}$ & $\ket{011}$ \\
    $\ket{100}$ & $\ket{100}$ \\
    $\ket{101}$ & $\ket{101}$ \\
    $\ket{110}$ & $\ket{111}$ \\
    $\ket{111}$ & $\ket{110}$ \\
    $\alpha \ket{000} + \beta \ket{001} + \gamma \ket{010} + \delta \ket{011}$ & $\alpha \ket{000} + \beta \ket{001} + \gamma \ket{010} + \delta \ket{011}$ \\
    $+ \epsilon \ket{100} + \zeta \ket{101} + \eta \ket{110} + \theta \ket{111}$ & $+ \epsilon \ket{100} + \zeta \ket{101} + \theta \ket{110} + \eta \ket{111}$
\end{tabular}
\end{center}

\subsection{Compuerta de Deutsch}

\begin{minipage}{0.5\textwidth}
    \[
        \Qcircuit @C=1.4em @R=1.8em {
        & \multigate{2}{D(\theta)} & \qw \\
        & \ghost{D(\theta)} & \qw \\
        & \ghost{D(\theta)} & \qw
        }
    \]
\end{minipage}
\begin{minipage}{0.5\textwidth}
    \[
        \begin{pmatrix}
            1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 & 0 & i \cos(\theta) & \sin(\theta) \\
            0 & 0 & 0 & 0 & 0 & 0 & \sin(\theta) & i \cos(\theta)
        \end{pmatrix}
    \]
\end{minipage}

\[
    \ket{a,b,c} \rightarrow
    \begin{cases}
        i \cos(\theta) \ket{a,b,c} + \sin(\theta) \ket{a,b,c \oplus 1} & \text{si } a=b=1 \\
        \ket{a,b,c} & \text{en otro caso}
    \end{cases}
\]

\begin{center}
\begin{tabular}{c c}
    Entrada & Salida \\
    $\ket{000}$ & $\ket{000}$ \\
    $\ket{001}$ & $\ket{001}$ \\
    $\ket{010}$ & $\ket{010}$ \\
    $\ket{011}$ & $\ket{011}$ \\
    $\ket{100}$ & $\ket{100}$ \\
    $\ket{101}$ & $\ket{101}$ \\
    $\ket{110}$ & $i \cos(\theta) \ket{110} + \sin(\theta) \ket{111}$ \\
    $\ket{111}$ & $\sin(\theta) \ket{110} + i \cos(\theta) \ket{111}$ \\
    $\alpha \ket{000} + \beta \ket{001} + \gamma \ket{010} + \delta \ket{011}$ & $\alpha \ket{000} + \beta \ket{001} + \gamma \ket{010} + \delta \ket{011}$ \\
    $+ \epsilon \ket{100} + \zeta \ket{101} + \eta \ket{110} + \iota \ket{111}$ & $+ \epsilon \ket{100} + \zeta \ket{101} + (i \cos(\theta) \eta + \sin(\theta) \iota) \ket{110}$ \\
    & $+ (\sin(\theta) \eta + i \cos(\theta) \iota) \ket{111}$
\end{tabular}
\end{center}

\section{Conjuntos universales de compuertas cuánticas}
Un conjunto universal de compuertas cuánticas (CUCC) es un conjunto finito de compuertas cuánticas con el cuál se puede aproximar cualquier operación unitaria arbitrariamente bien.

Cualquier operador unitario puede ser escrito en función de compuertas de uno y dos qubits \cite{barenco}.

Un CUCC simple es $\{H,T,\mathit{CNOT}\}$.

Existe un CUCC de una sóla compuerta, la compuerta de Deutsch, $D(\theta)$.

La compuerta de Toffoli es un caso especial de la compuerta de Deutsch, $D(\frac{\pi}{2})$.

Otro CUCC consiste en la compuerta de Ising y la compuerta de cambio de fase, \{$\mathit{XX}_\phi,R_z(\theta)$\}. Este conjunto es nativo en algunas computadoras cuánticas de trampas de iones.

\section{Criterios de DiVincenzo}
Para construir un computador cuántico, se deben cumplir las siguientes condiciones experimentales:

\begin{enumerate}
    \item Un sistema físico escalable con qubits bien caracterizados.
    \item La habilidad de inicializar el estado de los qubits en un estado fiducial simple.
    \item Tiempos de coherencia relevantes largos.
    \item Un conjunto universal de compuertas cuánticas.
    \item La capacidad de medir qubits en específico.
\end{enumerate}

\section{Fidelidad}

La fidelidad de dos distribuciones clasicas de probabilidad $\{p_x\}$ y $\{q_x\}$ es una medida de distancia entre ellas, y se define como:

\begin{equation}
    F(p_x, q_x) = \sum\limits_x \sqrt{p_x q_x}
\end{equation}

Cuando las distribuciones $\{p_x\}$ y $\{q_x\}$ son idénticas, la fidelidad entre ellas es igual a 1. La interpretación geométrica de la fidelidad es que esta es el producto interno de dos vectores de componentes $\sqrt{p_x}$ y $\sqrt{q_x}$, que yacen en la esfera unitaria.

En el caso de los estados cuánticos, la fidelidad toma la siguiente forma [ref]

\begin{equation}
    F(\rho, \sigma) = Tr(\sqrt{\rho^{1/2} \sigma \rho^{1/2}})
\end{equation}

\color{red}
La raiz de un operador se determina, a partir de su descomposición espectral, de ...
\color{black}

En ciertos casos especiales, la fidelidad se puede simplificar de las siguientes maneras:

\begin{enumerate}
    \item Si $\rho$ y $\sigma$ conmutan, es decir, que existe una base en la que ambos son diagonales, entonces la fidelidad cuántica toma la forma de la fidelidad clásica

        \begin{equation}
            F(\rho, \sigma) = Tr(\sum\limits_i \sqrt{r_i s_i} \ketbra{i}{i}) = \sum\limits_i \sqrt{r_i s_i} = F(r_i, s_i)
        \end{equation}

        Donde $r_i$ y $s_i$ son los autovalores de $\rho$ y $\sigma$, respectivamente.

    \item Si $\sigma$ es un estado puro $\ket{\psi}$, entonces la fidelidad toma la forma

        \begin{equation}
            F(\ket{\psi}, \rho) = Tr(\sqrt{\bra{\psi} \rho \ket{\psi} \braket{\psi}{\psi}}) = \sqrt{\bra{\psi} \rho \ket{\psi}}
        \end{equation}

    \item Si ambos estados son puros, entonces la fidelidad es:

        \begin{equation}
            F(\ket{\psi}, \ket{\varphi}) = \sqrt{\bra{\psi} \ketbra{\varphi}{\varphi} \ket{\psi}} = \abs{\braket{\psi}{\varphi}}
        \end{equation}
\end{enumerate}

\section{Medidas proyectivas}

El esquema de medidas proyectivas, también llamadas medidas de von Neumann, se encuentra formado por proyectores ortogonales asociados a la medida espectral de un observable \cite{sttiwuer}. Este esquema es uno de los tipos de medidas de uso más común, ya que está directamente asociada a la medición de una propiedad del sistema o un conjunto compatible de ellas, y tales propiedades son caracterizadas a través de operadores autoadjuntos. Esta medida fue empleada por von Neumann para descomponer a los observables de un sistema cuántico en una combinación lineal de proyectores, donde cada proyector está a asociado a lso subespacios $\mathcal{M}_\lambda$ que son dejados invariantes por el operador en cuestión y, los coeficientes de la combinación lineal corresponden a los posibles valores que arroja el observable tras una medición. En este esquema, la probabilidad $P_\lambda(p)$ de obtener un valor $\lambda \in \Delta$ después de medir el observable en cuestión en el estado $\hat{\rho}$ viene dada por el valor medio del proyector $\hat{\Pi}_{\mathcal{M}_\lambda}$ asociado al autovalor $\lambda$, mientras que el estado después de la medida viene dado por el autovector correspondiente a dicho autovalor. En este caso, las medidas proyectivas vienen dadas por

\begin{equation}
    \begin{array}{r}
    MP_s = \{\hat{\Pi}_m: \mathcal{H} \rightarrow \mathcal{M}_{\lambda_m} \subseteq \mathcal{H} \text{ tal que } \hat{\Pi}_m \hat{\Pi}_n = \delta_{m,n} \hat{\Pi_m}, \\
    \sum\limits_m \hat{\Pi}_m = \mathds{1}, P_{\lambda_m}(\rho) = (\hat{\Pi}_m)_\rho \text{ y } \rho_{\lambda_m} \xrightarrow{\text{colapso}} \hat{\Pi}_m\}
    \end{array}
\end{equation}

Cabe destacar que al realizar nuevamente la medida el estado resultante no se modifica, siempre que la dimensión de $\mathcal{M}_\lambda$ sea igual a uno, es decir, el proyector $\hat{\Pi}_{\mathcal{M}_\lambda}$ sea de rango uno. Este hecho se conoce con el nombre de repetibilidad, propiedad que no está presente en los otros esquemas de medidas.

\section{Sistemas cuánticos abiertos}

Consideremos el espacio de Hilbert bipartito $\mathcal{H} = \mathcal{H}_A \otimes \mathcal{H}_B$. Como ya vimos antes, si tenemos una matriz de densidad $\rho \in \mathcal{H}$, la manera de escribir la matriz de densidad del subsistema $A$ está dada por la traza parcial $\rho_A = Tr_B(\rho)$.

En $\mathcal{H}_A$ las medidas están dadas por un conjunto de operadores hermíticos $\{M_k\}$, cada uno de ellos asociado a un posible resultado $k$. Supongamos que no podemos ver el subsistema $B$ y que sólo vemos $A$ con $\rho_A$. Entonces, la probabilidad de obtener un resultado $k$ cuando realicemos la medida $\{M_k\}$ será

\begin{equation}
    p_A(k) = Tr(M_k \rho_A)
\end{equation}

En el sistema total esta medida corresponde a un operador $\tilde{M}_k = M_k \otimes \mathds{1}$ y la probabilidad de obtener el resultado $k$ sería

\begin{equation}
    p_A(k) = Tr(\tilde{M}_k \rho)
\end{equation}

Si $\{\ket{\psi_i^A}, \ket{\varphi_j^B}\}$ es una base de $\mathcal{H}$, entonces

\begin{equation}
    \begin{array}{r c l}
        p_A(k)
        &=& Tr[(M_k \otimes \mathds{1}) \rho] \\
        &=& \sum_{ij} \bra{\psi_i^A} \bra{\varphi_j^B} (M_k \otimes \mathds{1}) \rho \ket{\psi_i^A} \ket{\varphi_j^B} \\
        &=& \sum_i (\bra{\psi_i^A} M_k \otimes \mathds{1}) \left[\sum_j (\mathds{1} \otimes \bra{\varphi_j^B}) \rho (\mathds{1} \otimes \ket{\varphi_j^B})\right] (\ket{\psi_i^A} \otimes \mathds{1}) \\
        &=& \sum_i \bra{\psi_i^A} M_k Tr_B(\rho) \ket{\psi_i^A} \\
        &=& \sum_i \bra{\psi_i^A} M_k \rho_A \ket{\psi_i^A} = Tr(M_k \rho_A)
    \end{array}
\end{equation}

Así que $\rho_A$ está inequívocamente dado por la traza parcial $Tr_B(\rho)$.

Una propiedad importante de la traza parcial es que incluso si $\rho$ es un estado puro, $\rho_A$ y $\rho_B$ pueden ser mixtos, esto ocurre si $\ket{\phi}$ es un estado entrelazado.

Dada la matriz de densidad $\rho(t_0)$, tomando la traza parcial en $B$ en el tiempo $t_1$, tendríamos el estado $\rho_A(t_1)$, dado por:

\begin{equation}
    \rho_A(t_1) = Tr_B[U(t_1, t_0) \rho(t_0) U^\dagger(t_1, t_0)]
    \label{eq:parevol}
\end{equation}

Si el operador de evolución no puede ser factorizado de la manera $U(t_1, t_0) = U_A(t_1, t_0) \otimes U_B(t_1, t_0)$, entonces los sistemas $A$ y $B$ están iteractuando e intercambian energía e información entre ellos, es decir, son sistemas cuánticos abiertos.

Ahora, ?`qué pasa si queremos estudiar sólo la dinámica de $\rho_A$?, a pesar de saber que no podemos factorizar $U(t_1, t_0)$ en dos particiones. Este problema se soluciona desarrollando un mapa dinámico que actúe en $\mathcal{H}_A$ que transforme los estados del subsistema $A$ del tiempo $t_0$ al tiempo $t_1$.

\begin{equation}
    \mathcal{E}_{(t_1, t_0)} : \rho_A(t_0) \rightarrow \rho_A(t_1)
\end{equation}

El problema es que en general este mapa no depende sólo de $U(t_1, t_0)$ y de las propiedades de $B$, sino también de $A$ en sí mismo. Para aclarar este punto, escribamos el estado total $\rho$ como la suma de dos contribuciones:

\begin{equation}
    \rho(t_) = \rho_A(t_0) \otimes \rho_B(t_1) + \rho_{corr}(t_0)
    \label{eq:ABcorr}
\end{equation}

Donde el término $\rho_{corr}(t_0)$ no es un estado cuántico y satisface

\begin{equation}
    Tr_A[\rho_{corr}(t_0)] = Tr_B[\rho_{corr}(t_0)] = 0
\end{equation}

Este término contiene las correlaciones, tanto clásicas como cuánticas, entre los dos subsistemas. Sustituyendo  \ref{eq:ABcorr} en \ref{eq:parevol} tenemos

\begin{equation}
    \begin{array}{r c l}
        \rho_A(t_1)
        &=& Tr_B[U(t_1, t_0) (\rho_A(t_0) \otimes \rho_B(t_0) + \rho_{corr}(t_0)) U^\dagger(t_1, t_0)] \\
        &=& \sum_i \lambda_i Tr_B[U(t_1, t_0) (\rho_A(t_0) \otimes \ketbra{\psi_i}) U^\dagger(t_1, t_0)] \\ &+& Tr_B[U(t_1, t_0) \rho_{corr}(t_0)) U^\dagger(t_1, t_0)] \\
        &=& \sum_{ij} K_{ij}(t1, t0) \rho_A(t_0) K_{ij}^\dagger(t_1, t_0) + \zeta(t_1, t_0) \\
        &=& \mathcal{E}_{(t_1, t_0)}[\rho_A(t_0)]
    \end{array}
\end{equation}

Donde $K_{ij}(t_1, t_0) = \sqrt{\lambda_i} \bra{\psi_j} U(t_1, t_0) \ket{\psi_i}$ y hemos usado la descomposición espectral de $\rho_B(t_0) = \sum_i \lambda_i \ketbra{\psi_i}$. Los operadores $K_{ij}(t_1, t_0)$ dependen sólo del operador de evolución global y del estado inicial del subsistema $B$, pero la parte no homogenea $\zeta(t_1, t_0) = Tr_B[U(t_1, t_0) \rho_{corr}(t_0)) U^\dagger(t_1, t_0)]$ puede no ser independiente de $\rho_A$ debido al término de correlación $\rho_{corr}$.

Vista esta depencia, reescribamos $\mathcal{E}_{(t_1, t_0)}$ de la siguiente manera:

\begin{equation}
    \mathcal{E}_{(t_1, t_0)}[\rho_A] = \rho_A(t_1) = \sum_{ij} K_{ij}(t_1, t_0, \rho_A) \rho_A(t_0) K^\dagger_{ij}(t_1, t_0, \rho_A)
\end{equation}

Hemos escrito el mapa dinámico de manera homogenea y ahora $K_{ij}$ depende de $\rho_A$ en el tiempo $t_0$. Un mapa con esta forma siempre existe. Para demostrar esto, basta con considerar el siguiente caso particular:

\begin{equation}
    \mathcal{E}_{(t_1, t_0)}[\rho_A] = Tr_2[U_{SWAP} \rho_A(t_0) \otimes \rho_A(t_1) U_{SWAP}^\dagger] = \rho_A(t_1)
\end{equation}

Aquí $U_{SWAP}$ representa el operador SWAP entre las particiones 1 y 2, tal que $U_{SWAP} (\rho \otimes \sigma) U_{SWAP}^\dagger$. Así, $\rho_A(t_1)$ pasa a la partición 1 y es el resultado de la traza parcial. Entonces, si utilizamos la descomposición espectral de $\rho_A(t_1)$ tendremos

\begin{equation}
    \begin{array}{r c l}
        \mathcal{E}_{(t_1, t_0)}[\rho_A]
        &=& Tr_2[U_{SWAP} \rho_A(t_0) \otimes \rho_A(t_1) U_{SWAP}^\dagger] \\
        &=& \sum_i \lambda_i Tr_2[U_{SWAP} \rho_A(t_0) \otimes \ket{\lambda_i} U_{SWAP}^\dagger] \\
        &=& \sum_{ij} K_{ij}(t_1, t_0, \rho_A) \rho_A(t_0) K^\dagger_{ij}(t_1, t_0, \rho_A)
    \end{array}
\end{equation}

Donde $K_{ij}(t_1, t_0, \rho_A) = \sqrt{\lambda_i} \bra{\lambda_j} U_{SWAP} \ket{\lambda_i}$. Cabe mencionar que esta descomposición no es única.

Un mapa dinámico universal es aquel que es independiente del estado al que se aplica. Los operadores $K_{ij}(t_1, t_0)$ que lo conforman se conocen como operadores de Krauss. Los mapas dinámicos universales son completamente positivos y los operadores de Krauss cumplen la siguiente propiedad

\begin{equation}
    \sum_{ij} K_{ij}^\dagger(t_1, t_0) K_{ij}(t_1, t_0) = \mathds{1}
\end{equation}

Decimos que un sistema tiene evolución markoviana cuando su evolución puede ser descrita por mapas dinámicos universales tales componibles de la siguiente manera:

\begin{equation}
    \mathcal{E}_{(t_2, t_0)} = \mathcal{E}_{(t_2, t_1)} \mathcal{E}_{(t_1, t_0)}
\end{equation}

Esta propiedad de composición se conoce como condición de divisibilidad. Típicamente, la evolución de los sistemas abiertos no es markoviana, porque se desarrollan correlaciones que hacen que el mapa dinámico que la describe no sea universal. Sin embargo, si el término $\rho_{corr}$ no afecta mucho la dinámica del sistema, un modelo markoviano puede dar una buena aproximación de la evolución temporal.

Consideremos entonces una evolución markoviana. Esto nos permite construir la siguiente ecuación de diferencias:

\begin{equation}
    \rho(t + \epsilon) - \rho(t) = [\mathcal{E}_{(t+\epsilon,0)} - \mathcal{E}_{(t,0)}] \rho(0) = [\mathcal{E}_{(t+\epsilon,t)} - \mathds{1}] \mathcal{E}_{(t,0)}[\rho(0)] = [\mathcal{E}_{(t+\epsilon,t)} - \mathds{1}] \rho(t)
\end{equation}

Si el límite cuando $\epsilon$ tiende a cero está bien definido, entonces podemos construir la ecuación diferencial de $\rho(t)$, llamada ecuación maestra:

\begin{equation}
    \frac{d\rho(t)}{dt} = \lim_{\epsilon \to 0} \frac{\rho(t+\epsilon) - \rho(t)}{\epsilon} = \lim_{\epsilon \to 0} \frac{[\mathcal{E} - \mathds{1}]}{\epsilon} \rho(t) = \mathcal{L}_t \rho(t)
\end{equation}

Donde hemos definido el generador de la evolución como:

\begin{equation}
    \mathcal{L}_t = \lim_{\epsilon \to 0} \frac{[\mathcal{E} - \mathds{1}]}{\epsilon}
\end{equation}

Sea $\{F_j, j = 1, ..., N^2\}$ una base ortonormal completa con respecto al producto interno de Hilbert-Schmidt $(F_n, F_m) = Tr(F_n^\dagger F_m) = \delta_{nm}$, tal que $F_{N^2} = \mathds{1}/\sqrt{N}$, para que el resto de los operadores tengan traza cero. Ahora la expansión de Krauss en esta base nos da

\begin{equation}
    \mathcal{E}_{(t_2, t_1)}[\rho] = \sum_{nm} c_{nm}(t_2, t_1) F_n \rho F_m^\dagger
\end{equation}

Donde los elementos $c_{nm}$ son la multiplicación de los productos internos de $K_{ij}$ con los elementos de la base elegida.

\begin{equation}
    c_{nm}(t_2, t_1) = \sum_{ij} (F_n, K_{ij}(t_2, t_1)) (F_m, K_{ij}(t_2, t_1))^*
\end{equation}

En esta base el generador $\mathcal{L}_t$ toma la siguiente forma:

\begin{equation}
    \begin{array}{r c l}
        \mathcal{L}_t(\rho)
        &=& \lim_{\epsilon \to 0} \sum_{nm} \frac{c_{nm}(t+\epsilon,t) F_n \rho F_m^\dagger - \rho}{\epsilon} \\
        &=& \lim_{\epsilon \to 0}
        [\frac{c_{N^2N^2}(t+\epsilon,t) - N}{N\epsilon} \rho \\
        &+& \sum_{n=1}^{N^2-1} \frac{1}{\sqrt{N}} (
        \frac{c_{nN^2}(t+\epsilon,t)}{\epsilon} F_n \rho +
        \frac{c_{N^2n}(t+\epsilon,t)}{\epsilon} \rho F_n^\dagger) \\
        &+& \sum_{n,m=1}^{N^2-1} \frac{c_{nm}(t+\epsilon,t)}{\epsilon} F_n \rho F_m^\dagger]
    \end{array}
\end{equation}

Ahora, definamos los coeficientes $\alpha_{nm}(t)$ como:

\begin{align}
    \alpha_{N^2N^2}(t) &= \lim_{\epsilon \to 0} \frac{c_{N^2N^2}(t+\epsilon,t) - N}{\epsilon} \\
    \alpha_{nN^2}(t) &= \lim_{\epsilon \to 0} \frac{c_{nN^2}{\epsilon}}, \quad n = 1, ... , N^2 -1 \\
    \alpha_{nm}(t) &= \lim_{\epsilon \to 0} \frac{c_{nm}{\epsilon}}, \quad n = 1, ... , N^2 -1
\end{align}

También definimos los siguientes operadores:

\begin{align}
    F(t) &= \frac{1}{\sqrt{N}} \sum_{n=1}^{N^2-1} \alpha_{jN^2}(t) F_j \\
    G(t) &= \frac{\alpha_{N^2N^2}}{2N} \mathds{1} + \frac{1}{2} [F^\dagger(t) + F(t)] \\
    H(t) &= \frac{1}{2i} [F^\dagger(t) - F(t)]
\end{align}

Este último operador, $H(t)$, es hermítico. En términos de estos operadores, sustituyendo, el generador de la ecuación maestra toma la siguiente forma:

\begin{equation}
    \mathcal{L}_t(\rho) = -i [H(t), \rho] + \{G(t), \rho\} + \sum_{n,m=1}^{N^2-1} \alpha_{nm}(t) F_n \rho F_m^\dagger
\end{equation}

Ya que los mapas dinámicos universales preservan la traza de cualquier matriz de densidad $\rho$,

\begin{equation}
    0 = Tr[\mathcal{L}(\rho)] = Tr\left[ \left(2G(t) + \sum_{n,m=1}^{N^2-1} \alpha_{nm}(t) F_m^\dagger F_n \right) \rho \right]
\end{equation}

Las siguientes propiedades de la traza de los conmutadores y los anticonmutadores

\begin{align}
    Tr([A,B]) &= Tr(AB - BA) = Tr(AB) - Tr(BA) = 0 \\
    Tr(\{A,B\}) &= Tr(AB + BA) = Tr(AB) + Tr(BA) = 2 Tr(AB)
\end{align}

Dado este hecho, podemos concluir que 

\begin{equation}
    G(t) = - \frac{1}{2} \sum_{n,m=1}^{N^2-1} \alpha_{nm}(t) F_m^\dagger F_n
\end{equation}

Sustituyendo, el generador nos queda de con la siguiente forma

\begin{equation}
    \mathcal{L}_t(\rho) = -i [H(t), \rho] + \sum_{n,m=1}^{N^2-1} \alpha_{nm}(t) \left[F_n \rho F_m^\dagger - frac{1}{2} \{F_m^\dagger F_n, \rho\}\right]
\end{equation}

La matriz de coeficientes $\{\alpha_{nm}(t)\}$ es una matriz semidefinida positiva, así que podemos diagonalizarla con una matriz unitaria $u(t)$, tal que

\begin{equation}
    \sum_{nm} u_{jn}(t) \alpha_{nm}(t) u_{km}^*(t) = \gamma_j(t) \delta_{jk}
\end{equation}

Cada autovalor $\gamma_j(t)$ es mayor o igual a cero. Ahora tenemos los nuevos operadores $V_m(t)$

\begin{equation}
    V_m(t) = \sum_{n=1}^{N^2-1} u_{mn}^*(t) F_n \\
    F_j = \sum_{m=1}^{N^2-1} u_{mn}(t) V_m(t)
\end{equation}

Con estos últimos operadores, el generador de la ecuación maestra se convierte en

\begin{equation}
    \mathcal{L}_t(\rho) = -i [H(t), \rho] + \sum_m \gamma_m(t) \left[ V_m(t) \rho V_m^\dagger(t) - \frac{1}{2} \{V_m^\dagger(t) V_m(t), \rho\}\right]
\end{equation}

Con $\gamma_m(t) \geq 0$ para todo $m$ y $t$. Finalmente, Kossakowski \cite{Kossakowski_1972} y Lindblad \cite{Lindblad_1976} analizaron este problema para el caso de ecuaciones temporalmente homogeneas, es decir, el caso en el que el mapa dinámico universal depende sólo de la diferencia entre los tiempos $t_2$ y $t_1$, $\tau = t_2 - t_1$, en lugar de los tiempos en sí mismos, $\mathcal{E}_{(t2, t1)} = \mathcal{E}_{(\tau})$. La ecuación diferencial generada en este caso se conoce como Lindbladiano.

\begin{equation}
    \dot{\rho}(t) = -i [\hat{H}, \rho(t)] + \sum_k \gamma_k [V_k \rho(t) V_k^\dagger - \frac{1}{2} \{V_k^\dagger V_k, \rho(t)\}]
\end{equation}

En esta ecuación $\hat{H}$ es el Hamiltoniano del sistema, $V_k$ son operadores de salto o colapso, y $\gamma_k$ son tasas de decaimiento. El término $-i [\hat{H}, \rho(t)]$ representa la evolución unitaria y es el mismo de la ecuación de Liouville-von Neumann. Los términos $\gamma_k V_k \rho(t) V_k^\dagger$ representan el efecto del entorno en el sistema y los términos $-\frac{1}{2} \{V_k^\dagger V_k, \rho(t)\}$ son términos de normalización para el caso en el que el entorno no afecta al sistema.



